{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".hdf5\n",
      "Keys: <KeysViewHDF5 ['distances', 'neighbors', 'test', 'train']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"data/sift/sift-128-euclidean.hdf5\", \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    distances = list(f.keys())[0]\n",
    "    neighbors = list(f.keys())[1]\n",
    "    test = list(f.keys())[2]\n",
    "    train = list(f.keys())[3]\n",
    "\n",
    "    # Get the data\n",
    "    train = list(f[train])\n",
    "    distances = list(f[distances])\n",
    "    neighbors = list(f[neighbors])\n",
    "    test = list(f[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 10000 test vectors\n",
    "# for each of those vectors we have their 100 closest neighbors in order from closest to farthest\n",
    "# we also have their distances away from each of these 100 neighbors\n",
    "len(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the quantized vectors and codebooks\n",
    "# create the approximate vectors in place (retaining indices)\n",
    "# take that X and do np.argmin(np.linalg.norm(X - queries))\n",
    "from collections import defaultdict\n",
    "\n",
    "def readQuantAndCodes(rootDirectory, M):\n",
    "    quantFile = rootDirectory + \"quantized.txt\"\n",
    "    codesFile = rootDirectory + \"codebooks.txt\"\n",
    "    quantizedVectors = []\n",
    "    codebooks = defaultdict(list)\n",
    "    with open(quantFile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            quantizedVectors.append([int(x) for x in line.split(\" \")])\n",
    "\n",
    "    with open(codesFile, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        codebook_index = 0\n",
    "        for line in lines:\n",
    "            centroids_in_column = []\n",
    "            whole_line_as_ints = [float(x) for x in line.split(\" \")]\n",
    "            index = 0\n",
    "            for i in range(256):\n",
    "                centroid = []\n",
    "                for j in range(M):\n",
    "                    centroid.append(whole_line_as_ints[index])\n",
    "                    index += 1\n",
    "                codebooks[codebook_index].append(centroid)\n",
    "            codebook_index += 1\n",
    "\n",
    "    return quantizedVectors, codebooks\n",
    "\n",
    "\n",
    "for M in [50]:\n",
    "    quantizedVectors, codebooks = readQuantAndCodes(f\"data/word2vec/testing/testing_M{M}/\", M)\n",
    "    full_quantized = []\n",
    "    for vector in quantizedVectors:\n",
    "        actual_vector = []\n",
    "        for i in range(len(vector)):\n",
    "            for code in codebooks[i][vector[i]]:\n",
    "                actual_vector.append(code)\n",
    "        full_quantized.append(actual_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.751, 0.174, 0.219, 1.721, -0.937, -1.687, 0.905, 2.756, -1.246, -0.936, 1.139, 0.694, -0.446, -0.469, 0.176, 1.884, 3.43, -0.211, 1.094, 0.182, 0.831, 0.247, 2.08, -0.513, -0.321, 0.711, -1.464, -0.552, -1.052, -1.873, -0.448, 1.896, 0.85, 0.129, 1.833, -1.435, -1.563, 0.187, -0.466, 0.511, -0.274, 0.538, -2.065, 1.83, -0.777, -0.52, -3.648, 1.071, 1.042, -1.531]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(full_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec45d513f91af3fa73d2a6491e4593b2144b3268bc664facfb4253809511fada"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
